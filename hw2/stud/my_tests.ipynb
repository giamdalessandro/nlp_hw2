{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('nlp_hw2': venv)"
  },
  "interpreter": {
   "hash": "35bf5652c149c8ef1d689001f7b21f133df127512c57592ea276e1e13d983d75"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# POS tagging"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "\n",
    "if not os.path.isdir(\"../../data/nltk/\"):\n",
    "\t# check whether nltk data are already downloaded\n",
    "    nltk.download(\"averaged_perceptron_tagger\", download_dir=\"../../data/nltk/\")  # textblob\n",
    "    nltk.download(\"subjectivity\", download_dir=\"../../data/nltk/\")                # nltk.subjectivity\n",
    "# to load from file\n",
    "nltk.data.path.append(\"../../data/nltk/\")"
   ]
  },
  {
   "source": [
    "## textBlob"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "text = '''The titular threat of The Blob has always struck me as the ultimate movie\n",
    "monster: an insatiably hungry, amoeba-like mass able to penetrate\n",
    "virtually any safeguard, capable of--as a doomed doctor chillingly\n",
    "describes it--\"assimilating flesh on contact.\n",
    "Snide comparisons to gelatin be damned, it's a concept with the most\n",
    "devastating of potential consequences, not unlike the grey goo scenario\n",
    "proposed by technological theorists fearful of\n",
    "artificial intelligence run rampant.'''\n",
    "\n",
    "# ortography changes resulting pos_tags \n",
    "text2 = \"the movie begins in the past where a boy named sam attempts to save celebi from a hunter.\"\n",
    "\n",
    "blob = TextBlob(text2)\n",
    "\n",
    "# to get pos_tags\n",
    "blob.tags\n",
    "# to get noun phrases\n",
    "#blob.noun_phrases "
   ]
  },
  {
   "source": [
    "## nltk"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('the', 'DT'),\n",
       " ('movie', 'NN'),\n",
       " ('begins', 'VBZ'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('past', 'NN'),\n",
       " ('where', 'WRB'),\n",
       " ('a', 'DT'),\n",
       " ('boy', 'NN'),\n",
       " ('named', 'VBN'),\n",
       " ('sam', 'JJ'),\n",
       " ('attempts', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('save', 'VB'),\n",
       " ('celebi', 'NN'),\n",
       " ('from', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('hunter.', 'NN')]"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "\n",
    "n_instances = 100\n",
    "subj_docs = [(sent, 'subj') for sent in subjectivity.sents(categories='subj')[:n_instances]]\n",
    "obj_docs  = [(sent, 'obj') for sent in subjectivity.sents(categories='obj')[:n_instances]]\n",
    "\n",
    "#subj_docs[0], obj_docs[0]\n",
    "#len(subj_docs), len(obj_docs)\n",
    "\n",
    "tags = nltk.pos_tag(obj_docs[0][0])\n",
    "tags\n",
    "\n",
    "text2 = \"the movie begins in the past where a boy named sam attempts to save celebi from a hunter.\"\n",
    "nltk.pos_tag(text2.strip().split(\" \"))"
   ]
  },
  {
   "source": [
    "# Named-Entity Recognition"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## pre-trained embeddings"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([400000, 50])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "import torchtext\n",
    "\n",
    "vec = torchtext.vocab.GloVe(name='6B', dim=50)\n",
    "\n",
    "tokens = ['<UNK>']\n",
    "vec.get_vecs_by_tokens(tokens, lower_case_backup=True)\n",
    "\n",
    "vec.vectors.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}